from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware # í†µí–‰ì¦ ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

# ğŸ CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì ‘ì† í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # ëª¨ë“  ê³³ì—ì„œ ì˜¤ëŠ” ìš”ì²­ì„ í—ˆìš© (í…ŒìŠ¤íŠ¸ìš©)
    allow_credentials=True,
    allow_methods=["*"], # GET, POST ë“± ëª¨ë“  ë°©ì‹ í—ˆìš©
    allow_headers=["*"], # ëª¨ë“  í—¤ë” í—ˆìš©
)

if api_key:
    llm = ChatOpenAI(api_key=api_key, model="gpt-4o-mini")
    print(f"âœ… í‚¤ ë¡œë“œ ì„±ê³µ: {api_key[:10]}...")
else:
    llm = None
    print("âŒ í‚¤ ë¡œë“œ ì‹¤íŒ¨")

@app.get("/")
def home():
    return {"status": "ì„œë²„ ê°€ë™ ì¤‘"}

@app.get("/chat")
async def chat(user_input: str):
    if not llm: return {"error": "API í‚¤ ì—†ìŒ"}
    # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•´ await ì‚¬ìš© (ê¶Œì¥)
    response = await llm.ainvoke(user_input) 
    return {"ai_answer": response.content}